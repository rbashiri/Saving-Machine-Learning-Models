{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1217a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Save Models in Scikit-Learn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Your training data\n",
    "X_train = np.array([[25, 50000], [45, 80000], [35, 60000], [50, 95000]])\n",
    "y_train = np.array([0, 1, 0, 1])\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b74b2a4",
   "metadata": {},
   "source": [
    "At this point, you have a trained model stored in the variable model. But this only exists in your computer's memory while your program is running. To save it to disk, you'll use joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f6fe43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer_prediction_model.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(model, 'customer_prediction_model.pkl') \n",
    "#Model Saving: Uses joblib.dump() to save the trained model to a file called customer_prediction_model.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988bfc8d",
   "metadata": {},
   "source": [
    "That's it! You've just saved your model to a file called customer_prediction_model.pkl. The .pkl extension stands for \"pickle,\" which is the name of Python's serialization format. This file now contains everything your model learned during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed092901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# Loading Your Saved Model\n",
    "import joblib\n",
    "\n",
    "# Load the model from the file\n",
    "# Model Loading: Shows how to load the saved model back from the file using joblib.load()\n",
    "loaded_model = joblib.load('customer_prediction_model.pkl')# joblib.load\n",
    "\n",
    "# Now you can use it to make predictions\n",
    "new_customer = [[30, 55000]]  # Age 30, income $55,000\n",
    "prediction = loaded_model.predict(new_customer)\n",
    "print(prediction)  # Will output 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3574f1",
   "metadata": {},
   "source": [
    "**The area you have selected appears to be part of the model saving/loading section. This is a common workflow in machine learning where you**:\n",
    "\n",
    "1. Train a model once (which can be time-consuming)\n",
    "2. Save it to disk so you don't have to retrain it every time\n",
    "3. Load it later to make predictions on new data\n",
    "4. The .pkl file extension stands for \"pickle\" - Python's built-in serialization format that allows you to store Python objects (like your trained model) to disk and reload them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01aa0a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 1.0\n",
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# A Complete Example\n",
    "# A Complete Example that includes training, saving, loading, and predicting\n",
    "from sklearn.datasets import load_iris  # is a built-in dataset in scikit-learn\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# load dataset\n",
    "iris = load_iris()\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size= 0.2, random_state= 42)\n",
    "\n",
    "# train model \n",
    "model = DecisionTreeClassifier(random_state = 42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# cehck its accuracy\n",
    "accuracy = model.score(x_test, y_test)\n",
    "print(f\"Model accuracy: {accuracy}\")\n",
    "\n",
    "# save the model\n",
    "joblib.dump(model, 'iris_classifier.pkl')\n",
    "print(\"Model saved successfully.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "113c600a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this flower is predicted to be type: 0\n"
     ]
    }
   ],
   "source": [
    "# Then, perhaps days later or in a different script entirely, you load and use the model:\n",
    "import joblib\n",
    "import numpy as np\n",
    "# load the saved model\n",
    "model= joblib.load('iris_classifier.pkl')\n",
    "\n",
    "# make a prediction\n",
    "new_flower = np.array([[5.1,3.5,1.5,0.2]])  # Example flower measurements\n",
    "prediction = model.predict(new_flower)\n",
    "print(f\"this flower is predicted to be type: {prediction[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c251d6e",
   "metadata": {},
   "source": [
    "## When you save a trained scikit-learn model using joblib, what exactly gets saved in the file?\n",
    "All the learned parameters and patterns from training, such as coefficients, weights, or tree structures. \n",
    "\n",
    "Excellent! The saved model contains all the results of training ‚Äî the weights, coefficients, tree structures, or whatever parameters the algorithm learned. This is why you can immediately make predictions without retraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b1693e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer churn data shape: X=(12, 2), y=(12,)\n",
      "Data ready for training!\n"
     ]
    }
   ],
   "source": [
    "# Create sample customer churn data for the example\n",
    "import numpy as np\n",
    "\n",
    "# Customer features: [age, income] \n",
    "X_train_churn = np.array([\n",
    "    [25, 50000], [45, 80000], [35, 60000], [50, 95000],\n",
    "    [28, 55000], [42, 75000], [38, 65000], [55, 100000],\n",
    "    [30, 52000], [48, 85000], [33, 58000], [52, 92000]\n",
    "])\n",
    "\n",
    "# Churn labels: 0 = stayed, 1 = churned\n",
    "y_train_churn = np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])\n",
    "\n",
    "print(f\"Customer churn data shape: X={X_train_churn.shape}, y={y_train_churn.shape}\")\n",
    "print(\"Data ready for training!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b3c376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model version 1 saved successfully.\n",
      "Model trained on 12 customer records\n"
     ]
    }
   ],
   "source": [
    "# Saving file in different versions\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train the first model using the customer churn data\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_churn, y_train_churn)\n",
    "\n",
    "# Save the model with version number\n",
    "version = 1\n",
    "joblib.dump(model, f'customer_churn_model_v{version}.joblib')\n",
    "print(f\"Model version {version} saved successfully.\")\n",
    "print(f\"Model trained on {len(X_train_churn)} customer records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bc59263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model version 2 saved successfully.\n",
      "Model v2 trained with 200 trees (vs 100 in v1)\n"
     ]
    }
   ],
   "source": [
    "# When we train a new version, just increment the version number\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train version 2 with different hyperparameters (more trees)\n",
    "model_v2 = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "model_v2.fit(X_train_churn, y_train_churn)  # Use the same data but different model settings\n",
    "\n",
    "# Save the new version\n",
    "version = 2\n",
    "joblib.dump(model_v2, f'customer_churn_model_v{version}.joblib')\n",
    "print(f\"Model version {version} saved successfully.\")\n",
    "print(f\"Model v{version} trained with {model_v2.n_estimators} trees (vs 100 in v1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997fe7c6",
   "metadata": {},
   "source": [
    "**MAJOR.MINOR.PATCH**\n",
    "* The MAJOR version changes when you make a breaking change. \n",
    "* The MINOR version changes when you make improvements that don't break compatibility.\n",
    "* The PATCH version changes for small fixes or adjustments. \n",
    "\n",
    "1. Your first production model\n",
    "    * version = \"1.0.0\"\n",
    "    * joblib.dump(model, f'fraud_detection_model_v{version}.joblib')\n",
    "\n",
    "2.  Three months later: retrained with more data, better performance\n",
    "    * version = \"1.1.0\"\n",
    "    * joblib.dump(model, f'fraud_detection_model_v{version}.joblib')\n",
    "\n",
    "3.  Next week: fixed a preprocessing bug\n",
    "    * version = \"1.1.1\"\n",
    "    * joblib.dump(model, f'fraud_detection_model_v{version}.joblib')\n",
    "\n",
    "4.  Six months later: completely redesigned features, added new data sources\n",
    "    * version = \"2.0.0\"\n",
    "* joblib.dump(model, f'fraud_detection_model_v{version}.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ca1ff10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved with accuracy: 1.0000\n",
      "Both model and metadata saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Add these imports first\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Create the missing data variables (using the churn data from earlier in your notebook)\n",
    "X_train_churn = np.array([\n",
    "    [25, 50000], [45, 80000], [35, 60000], [50, 95000],\n",
    "    [28, 55000], [42, 75000], [38, 65000], [55, 100000],\n",
    "    [30, 52000], [48, 85000], [33, 58000], [52, 92000]\n",
    "])\n",
    "\n",
    "y_train_churn = np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1])\n",
    "# Create test data by splitting the training data\n",
    "X_train_churn, X_test_churn, y_train_churn, y_test_churn = train_test_split(\n",
    "    X_train_churn, y_train_churn, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train your model\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "model.fit(X_train_churn, y_train_churn)\n",
    "\n",
    "# Calculate performance\n",
    "accuracy = model.score(X_test_churn, y_test_churn)\n",
    "\n",
    "# Create metadata\n",
    "metadata = {\n",
    "    \"version\": \"1.2.0\",\n",
    "    \"model_type\": \"RandomForestClassifier\",\n",
    "    \"training_date\": datetime.now().strftime(\"%Y-%m-%d\"),\n",
    "    \"dataset\": \"customer_data_2025Q1.csv\",\n",
    "    \"n_samples\": len(X_train_churn),\n",
    "    \"accuracy\": round(accuracy, 4),\n",
    "    \"hyperparameters\": {\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 10,\n",
    "        \"random_state\": 42\n",
    "    },\n",
    "    \"description\": \"Retrained with Q1 data, added customer tenure feature\"\n",
    "}\n",
    "# Save the model\n",
    "joblib.dump(model, 'model_v1.2.0.joblib')\n",
    "\n",
    "# Save the metadata\n",
    "with open('model_v1.2.0_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(f\"Model saved with accuracy: {accuracy:.4f}\")\n",
    "print(\"Both model and metadata saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab449b6",
   "metadata": {},
   "source": [
    "**The progression would typically be**:\n",
    " * 1.0.0 - Original production model**\n",
    " * 1.1.0 - First improvement (maybe retrained with more data)**\n",
    " * 1.2.0 - Second improvement (this version - \"Retrained with Q1 data, added customer tenure feature\")**\n",
    "Looking at the metadata description: \"Retrained with Q1 data, added customer tenure feature\", this suggests:\n",
    "\n",
    "* They added a new feature (customer tenure)\n",
    "* They retrained with fresh Q1 2025 data\n",
    "* These are improvements that don't break existing code that uses the model\n",
    "* This is better than the model than version 1.1.0, but someone using version 1.1.0 could easily upgrade to 1.2.0 without changing their prediction * code - that's why it's a MINOR version bump, not a MAJOR one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c561f02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model version 1.2.0\n",
      "Trained on: 2025-12-24\n",
      "Accuracy: 1.0\n",
      "Description: Retrained with Q1 data, added customer tenure feature\n"
     ]
    }
   ],
   "source": [
    "# Now when you load your model later, you can also load its metadata to understand exactly what you're working with:\n",
    "# Load model and its metadata\n",
    "model = joblib.load('model_v1.2.0.joblib')\n",
    "\n",
    "with open('model_v1.2.0_metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(f\"Loaded model version {metadata['version']}\")\n",
    "print(f\"Trained on: {metadata['training_date']}\")\n",
    "print(f\"Accuracy: {metadata['accuracy']}\")\n",
    "print(f\"Description: {metadata['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ed5c41",
   "metadata": {},
   "source": [
    "# A Complete Versioning Workflow Example\n",
    "\n",
    "Let's walk through a realistic scenario where you train multiple versions of a model over time and see how versioning helps you stay organized.\n",
    "\n",
    "**Scenario:** You're building a model to predict whether customers will click on an ad. Here's your journey over 6 months:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b345db80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "January dataset: 4000 training samples, 1000 test samples\n",
      "Features: ['age', 'location', 'device_type']\n",
      "Click rate: 22.56%\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Create January dataset for Version 1.0.0\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create realistic January ad click data\n",
    "np.random.seed(42)\n",
    "n_samples_jan = 5000\n",
    "\n",
    "# Generate January data with basic features\n",
    "df_jan = pd.DataFrame({\n",
    "    'age': np.random.randint(18, 65, n_samples_jan),\n",
    "    'location': np.random.choice(['urban', 'suburban', 'rural'], n_samples_jan),\n",
    "    'device_type': np.random.choice(['mobile', 'desktop', 'tablet'], n_samples_jan),\n",
    "    # Create some realistic click patterns\n",
    "    'clicked': np.random.choice([0, 1], n_samples_jan, p=[0.78, 0.22])  # 22% click rate\n",
    "})\n",
    "\n",
    "# Prepare data for training\n",
    "le_location = LabelEncoder()\n",
    "le_device = LabelEncoder()\n",
    "\n",
    "X_jan = df_jan[['age', 'location', 'device_type']].copy()\n",
    "X_jan['location'] = le_location.fit_transform(X_jan['location'])\n",
    "X_jan['device_type'] = le_device.fit_transform(X_jan['device_type'])\n",
    "y_jan = df_jan['clicked']\n",
    "\n",
    "# Split the data\n",
    "X_train_jan, X_test_jan, y_train_jan, y_test_jan = train_test_split(\n",
    "    X_jan, y_jan, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"January dataset: {len(X_train_jan)} training samples, {len(X_test_jan)} test samples\")\n",
    "print(f\"Features: {list(X_jan.columns)}\")\n",
    "print(f\"Click rate: {y_jan.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "670e8073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Training Version 1.0.0 - Initial Model\n",
      "==================================================\n",
      "Model accuracy: 77.40%\n",
      "‚úÖ Version 1.0.0 saved!\n",
      "üìä Accuracy: 77.40%\n",
      "üíæ Files: ad_click_model_v1.0.0.joblib & ad_click_model_v1.0.0_metadata.json\n",
      "\n",
      "üéØ Result: Deployed to production. Works reasonably well!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Version 1.0.0 - Initial model in January\n",
    "print(\"üöÄ Training Version 1.0.0 - Initial Model\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Train initial model\n",
    "model_v1_0_0 = LogisticRegression(random_state=42)\n",
    "model_v1_0_0.fit(X_train_jan, y_train_jan)\n",
    "accuracy_v1_0_0 = model_v1_0_0.score(X_test_jan, y_test_jan)\n",
    "\n",
    "print(f\"Model accuracy: {accuracy_v1_0_0:.2%}\")\n",
    "\n",
    "# Save model\n",
    "version = \"1.0.0\"\n",
    "joblib.dump(model_v1_0_0, f'ad_click_model_v{version}.joblib')\n",
    "\n",
    "# Save metadata\n",
    "metadata_v1_0_0 = {\n",
    "    \"version\": version,\n",
    "    \"date\": \"2025-01-15\",\n",
    "    \"dataset\": \"ad_clicks_jan.csv\",\n",
    "    \"samples\": len(X_train_jan),\n",
    "    \"accuracy\": round(accuracy_v1_0_0, 4),\n",
    "    \"model_type\": \"LogisticRegression\",\n",
    "    \"features\": [\"age\", \"location\", \"device_type\"],\n",
    "    \"description\": \"Initial model with basic features: age, location, device type\"\n",
    "}\n",
    "\n",
    "with open(f'ad_click_model_v{version}_metadata.json', 'w') as f:\n",
    "    json.dump(metadata_v1_0_0, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Version {version} saved!\")\n",
    "print(f\"üìä Accuracy: {accuracy_v1_0_0:.2%}\")\n",
    "print(f\"üíæ Files: ad_click_model_v{version}.joblib & ad_click_model_v{version}_metadata.json\")\n",
    "print(\"\\nüéØ Result: Deployed to production. Works reasonably well!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d6e34a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Creating Q1 Dataset - March Update\n",
      "==================================================\n",
      "Q1 dataset: 12000 training samples, 3000 test samples\n",
      "Features: ['age', 'location', 'device_type'] (same as v1.0.0)\n",
      "Click rate: 25.23%\n",
      "üìä More data = better patterns to learn from!\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Create Q1 dataset for Version 1.1.0 (3 months of data)\n",
    "print(\"üìà Creating Q1 Dataset - March Update\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create Q1 data (3x more samples - January + February + March)\n",
    "np.random.seed(123)  # Different seed for more varied data\n",
    "n_samples_q1 = 15000\n",
    "\n",
    "df_q1 = pd.DataFrame({\n",
    "    'age': np.random.randint(18, 65, n_samples_q1),\n",
    "    'location': np.random.choice(['urban', 'suburban', 'rural'], n_samples_q1),\n",
    "    'device_type': np.random.choice(['mobile', 'desktop', 'tablet'], n_samples_q1),\n",
    "    'clicked': np.random.choice([0, 1], n_samples_q1, p=[0.75, 0.25])  # Better click rate with more data\n",
    "})\n",
    "\n",
    "# Prepare Q1 data\n",
    "X_q1 = df_q1[['age', 'location', 'device_type']].copy()\n",
    "X_q1['location'] = le_location.transform(X_q1['location'])\n",
    "X_q1['device_type'] = le_device.transform(X_q1['device_type'])\n",
    "y_q1 = df_q1['clicked']\n",
    "\n",
    "# Split the data\n",
    "X_train_q1, X_test_q1, y_train_q1, y_test_q1 = train_test_split(\n",
    "    X_q1, y_q1, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Q1 dataset: {len(X_train_q1)} training samples, {len(X_test_q1)} test samples\")\n",
    "print(f\"Features: {list(X_q1.columns)} (same as v1.0.0)\")\n",
    "print(f\"Click rate: {y_q1.mean():.2%}\")\n",
    "print(\"üìä More data = better patterns to learn from!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "706de32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Training Version 1.1.0 - More Data!\n",
      "==================================================\n",
      "Model accuracy: 74.83%\n",
      "‚úÖ Version 1.1.0 saved!\n",
      "üìä Accuracy: 74.83% (vs 77.40% in v1.0.0)\n",
      "üíæ Files: ad_click_model_v1.1.0.joblib & ad_click_model_v1.1.0_metadata.json\n",
      "üéØ Result: Better accuracy! Deploy v1.1.0 but keep v1.0.0 as backup.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Version 1.1.0 - Improvement in March (more data, same features)\n",
    "print(\"üîÑ Training Version 1.1.0 - More Data!\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Train with more data (same features)\n",
    "model_v1_1_0 = LogisticRegression(random_state=42)\n",
    "model_v1_1_0.fit(X_train_q1, y_train_q1)\n",
    "accuracy_v1_1_0 = model_v1_1_0.score(X_test_q1, y_test_q1)\n",
    "\n",
    "print(f\"Model accuracy: {accuracy_v1_1_0:.2%}\")\n",
    "\n",
    "# Save new version\n",
    "version = \"1.1.0\"\n",
    "joblib.dump(model_v1_1_0, f'ad_click_model_v{version}.joblib')\n",
    "\n",
    "metadata_v1_1_0 = {\n",
    "    \"version\": version,\n",
    "    \"date\": \"2025-03-20\",\n",
    "    \"dataset\": \"ad_clicks_q1.csv\",\n",
    "    \"samples\": len(X_train_q1),\n",
    "    \"accuracy\": round(accuracy_v1_1_0, 4),\n",
    "    \"model_type\": \"LogisticRegression\",\n",
    "    \"features\": [\"age\", \"location\", \"device_type\"],\n",
    "    \"description\": f\"Retrained with Q1 data, accuracy improved from {accuracy_v1_0_0:.2%} to {accuracy_v1_1_0:.2%}\"\n",
    "}\n",
    "\n",
    "with open(f'ad_click_model_v{version}_metadata.json', 'w') as f:\n",
    "    json.dump(metadata_v1_1_0, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Version {version} saved!\")\n",
    "print(f\"üìä Accuracy: {accuracy_v1_1_0:.2%} (vs {accuracy_v1_0_0:.2%} in v1.0.0)\")\n",
    "print(f\"üíæ Files: ad_click_model_v{version}.joblib & ad_click_model_v{version}_metadata.json\")\n",
    "print(f\"üéØ Result: Better accuracy! Deploy v{version} but keep v1.0.0 as backup.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "441f5977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí° Creating H1 Dataset - June Major Update\n",
      "==================================================\n",
      "H1 dataset: 20000 training samples, 5000 test samples\n",
      "Features: ['age', 'location', 'device_type', 'hour_of_day'] ‚Üê NEW: hour_of_day!\n",
      "Click rate: 32.70%\n",
      "‚ö†Ô∏è  BREAKING CHANGE: Old code expects 3 features, now we have 4!\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create H1 dataset for Version 2.0.0 (with NEW features!)\n",
    "print(\"üí° Creating H1 Dataset - June Major Update\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create H1 data with NEW FEATURE: hour_of_day (BREAKING CHANGE!)\n",
    "np.random.seed(789)\n",
    "n_samples_h1 = 25000\n",
    "\n",
    "df_h1 = pd.DataFrame({\n",
    "    'age': np.random.randint(18, 65, n_samples_h1),\n",
    "    'location': np.random.choice(['urban', 'suburban', 'rural'], n_samples_h1),\n",
    "    'device_type': np.random.choice(['mobile', 'desktop', 'tablet'], n_samples_h1),\n",
    "    'hour_of_day': np.random.randint(0, 24, n_samples_h1),  # NEW FEATURE!\n",
    "    # More sophisticated click patterns based on time\n",
    "    'clicked': np.random.choice([0, 1], n_samples_h1, p=[0.68, 0.32])  # Even better patterns\n",
    "})\n",
    "\n",
    "# Prepare H1 data with ALL features (including the new one)\n",
    "X_h1 = df_h1[['age', 'location', 'device_type', 'hour_of_day']].copy()\n",
    "X_h1['location'] = le_location.transform(X_h1['location'])\n",
    "X_h1['device_type'] = le_device.transform(X_h1['device_type'])\n",
    "y_h1 = df_h1['clicked']\n",
    "\n",
    "# Split the data\n",
    "X_train_h1, X_test_h1, y_train_h1, y_test_h1 = train_test_split(\n",
    "    X_h1, y_h1, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"H1 dataset: {len(X_train_h1)} training samples, {len(X_test_h1)} test samples\")\n",
    "print(f\"Features: {list(X_h1.columns)} ‚Üê NEW: hour_of_day!\")\n",
    "print(f\"Click rate: {y_h1.mean():.2%}\")\n",
    "print(\"‚ö†Ô∏è  BREAKING CHANGE: Old code expects 3 features, now we have 4!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11b99af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Training Version 1.1.0 - More Data!\n",
      "==================================================\n",
      "Model accuracy: 74.83%\n",
      "‚úÖ Version 1.1.0 saved!\n",
      "üìä Accuracy: 74.83% (vs 77.40% in v1.0.0)\n",
      "\n",
      "üöÄ Training Version 2.0.0 - MAJOR UPDATE!\n",
      "==================================================\n",
      "Model accuracy: 58.34%\n",
      "‚úÖ Version 2.0.0 saved!\n",
      "üìä Accuracy: 58.34% (vs 74.83% in v1.1.0)\n",
      "üíæ Files: ad_click_model_v2.0.0.joblib & ad_click_model_v2.0.0_metadata.json\n",
      "‚ö†Ô∏è  BREAKING: Requires 4 features instead of 3 + different algorithm\n",
      "üéØ Result: Best accuracy yet, but need to update production code!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, train Version 1.1.0 (missing from the notebook)\n",
    "print(\"üîÑ Training Version 1.1.0 - More Data!\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Train with more data (same features as 1.0.0)\n",
    "model_v1_1_0 = LogisticRegression(random_state=42)\n",
    "model_v1_1_0.fit(X_train_q1, y_train_q1)\n",
    "accuracy_v1_1_0 = model_v1_1_0.score(X_test_q1, y_test_q1)\n",
    "\n",
    "print(f\"Model accuracy: {accuracy_v1_1_0:.2%}\")\n",
    "\n",
    "# Save version 1.1.0\n",
    "version_v1_1 = \"1.1.0\"\n",
    "joblib.dump(model_v1_1_0, f'ad_click_model_v{version_v1_1}.joblib')\n",
    "\n",
    "metadata_v1_1_0 = {\n",
    "    \"version\": version_v1_1,\n",
    "    \"date\": \"2025-03-20\",\n",
    "    \"dataset\": \"ad_clicks_q1.csv\",\n",
    "    \"samples\": len(X_train_q1),\n",
    "    \"accuracy\": round(accuracy_v1_1_0, 4),\n",
    "    \"model_type\": \"LogisticRegression\",\n",
    "    \"features\": [\"age\", \"location\", \"device_type\"],\n",
    "    \"description\": f\"Retrained with Q1 data, accuracy improved from {accuracy_v1_0_0:.2%} to {accuracy_v1_1_0:.2%}\"\n",
    "}\n",
    "\n",
    "with open(f'ad_click_model_v{version_v1_1}_metadata.json', 'w') as f:\n",
    "    json.dump(metadata_v1_1_0, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Version {version_v1_1} saved!\")\n",
    "print(f\"üìä Accuracy: {accuracy_v1_1_0:.2%} (vs {accuracy_v1_0_0:.2%} in v1.0.0)\")\n",
    "print()\n",
    "\n",
    "# Now train Version 2.0.0 - Major redesign in June (NEW features + algorithm)\n",
    "print(\"üöÄ Training Version 2.0.0 - MAJOR UPDATE!\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Switch to RandomForest + new features (BREAKING CHANGES!)\n",
    "model_v2_0_0 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_v2_0_0.fit(X_train_h1, y_train_h1)\n",
    "accuracy_v2_0_0 = model_v2_0_0.score(X_test_h1, y_test_h1)\n",
    "\n",
    "print(f\"Model accuracy: {accuracy_v2_0_0:.2%}\")\n",
    "\n",
    "# Save major new version\n",
    "version = \"2.0.0\"\n",
    "joblib.dump(model_v2_0_0, f'ad_click_model_v{version}.joblib')\n",
    "\n",
    "metadata_v2_0_0 = {\n",
    "    \"version\": version,\n",
    "    \"date\": \"2025-06-10\",\n",
    "    \"dataset\": \"ad_clicks_h1_with_time.csv\",\n",
    "    \"samples\": len(X_train_h1),\n",
    "    \"accuracy\": round(accuracy_v2_0_0, 4),\n",
    "    \"model_type\": \"RandomForestClassifier\",\n",
    "    \"features\": [\"age\", \"location\", \"device_type\", \"hour_of_day\"],\n",
    "    \"breaking_changes\": [\"Added hour_of_day feature\", \"Changed from LogisticRegression to RandomForest\"],\n",
    "    \"description\": f\"Major update: added time-of-day feature, switched to Random Forest. Accuracy: {accuracy_v2_0_0:.2%}\"\n",
    "}\n",
    "\n",
    "with open(f'ad_click_model_v{version}_metadata.json', 'w') as f:\n",
    "    json.dump(metadata_v2_0_0, f, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Version {version} saved!\")\n",
    "print(f\"üìä Accuracy: {accuracy_v2_0_0:.2%} (vs {accuracy_v1_1_0:.2%} in v1.1.0)\")\n",
    "print(f\"üíæ Files: ad_click_model_v{version}.joblib & ad_click_model_v{version}_metadata.json\")\n",
    "print(f\"‚ö†Ô∏è  BREAKING: Requires 4 features instead of 3 + different algorithm\")\n",
    "print(f\"üéØ Result: Best accuracy yet, but need to update production code!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e596fa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä MODEL EVOLUTION SUMMARY\n",
      "============================================================\n",
      "ü•â Version 1.0.0: 77.40% accuracy (Jan - Basic model)\n",
      "ü•à Version 1.1.0: 74.83% accuracy (Mar - More data)\n",
      "ü•á Version 2.0.0: 58.34% accuracy (Jun - New features)\n",
      "============================================================\n",
      "\n",
      "üìÅ Your organized model directory:\n",
      "‚îú‚îÄ‚îÄ ad_click_model_v1.0.0.joblib\n",
      "‚îú‚îÄ‚îÄ ad_click_model_v1.0.0_metadata.json\n",
      "‚îú‚îÄ‚îÄ ad_click_model_v1.1.0.joblib\n",
      "‚îú‚îÄ‚îÄ ad_click_model_v1.1.0_metadata.json\n",
      "‚îú‚îÄ‚îÄ ad_click_model_v2.0.0.joblib\n",
      "‚îî‚îÄ‚îÄ ad_click_model_v2.0.0_metadata.json\n",
      "\n",
      "üéØ BENEFITS OF VERSIONING:\n",
      "‚úÖ Can rollback to v1.1.0 if v2.0.0 has issues\n",
      "‚úÖ Know exactly what changed between versions\n",
      "‚úÖ Can reproduce any previous model\n",
      "‚úÖ Track accuracy improvements over time\n",
      "‚úÖ Understand breaking changes before deployment\n",
      "\n",
      "üöÄ READY FOR PRODUCTION:\n",
      "- Deploy v2.0.0 for best accuracy (58.34%)\n",
      "- Keep v1.1.0 as backup (74.83%)\n",
      "- Archive v1.0.0 for historical reference (77.40%)\n"
     ]
    }
   ],
   "source": [
    "# Final Summary - Your Model Evolution Journey\n",
    "print(\"üìä MODEL EVOLUTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ü•â Version 1.0.0: {accuracy_v1_0_0:.2%} accuracy (Jan - Basic model)\")\n",
    "print(f\"ü•à Version 1.1.0: {accuracy_v1_1_0:.2%} accuracy (Mar - More data)\")  \n",
    "print(f\"ü•á Version 2.0.0: {accuracy_v2_0_0:.2%} accuracy (Jun - New features)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüìÅ Your organized model directory:\")\n",
    "print(\"‚îú‚îÄ‚îÄ ad_click_model_v1.0.0.joblib\")\n",
    "print(\"‚îú‚îÄ‚îÄ ad_click_model_v1.0.0_metadata.json\")\n",
    "print(\"‚îú‚îÄ‚îÄ ad_click_model_v1.1.0.joblib\") \n",
    "print(\"‚îú‚îÄ‚îÄ ad_click_model_v1.1.0_metadata.json\")\n",
    "print(\"‚îú‚îÄ‚îÄ ad_click_model_v2.0.0.joblib\")\n",
    "print(\"‚îî‚îÄ‚îÄ ad_click_model_v2.0.0_metadata.json\")\n",
    "\n",
    "print(\"\\nüéØ BENEFITS OF VERSIONING:\")\n",
    "print(\"‚úÖ Can rollback to v1.1.0 if v2.0.0 has issues\")\n",
    "print(\"‚úÖ Know exactly what changed between versions\") \n",
    "print(\"‚úÖ Can reproduce any previous model\")\n",
    "print(\"‚úÖ Track accuracy improvements over time\")\n",
    "print(\"‚úÖ Understand breaking changes before deployment\")\n",
    "\n",
    "print(f\"\\nüöÄ READY FOR PRODUCTION:\")\n",
    "print(f\"- Deploy v2.0.0 for best accuracy ({accuracy_v2_0_0:.2%})\")\n",
    "print(f\"- Keep v1.1.0 as backup ({accuracy_v1_1_0:.2%})\")\n",
    "print(f\"- Archive v1.0.0 for historical reference ({accuracy_v1_0_0:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0e2a20",
   "metadata": {},
   "source": [
    "**Key Principles** \n",
    "* As you start implementing versioning in your own projects, keep these principles in mind:\n",
    "\n",
    "* Always version from the start. Don't wait until you have multiple models to start versioning. Even your first model should be version 1.0.0. It's much easier to establish good habits early than to clean up a mess later.\n",
    "\n",
    "* Never overwrite model files. When you train a new version, save it with a new filename. Your old versions should remain untouched. Storage is cheap; losing track of which model was which is expensive.\n",
    "\n",
    "* Write descriptions when you save metadata. Future you will thank present you for writing a brief note about why you trained this version. \"Retrained with Q2 data, added customer age feature\" is far more helpful than nothing.\n",
    "\n",
    "* Keep a simple log. Consider keeping a text file or spreadsheet that lists all your model versions, when they were trained, and what changed. This gives you a quick reference without having to open every metadata file.\n",
    "\n",
    "* Test before deploying new versions. Just because a model has higher accuracy doesn't mean it's better in production. Sometimes models with slightly lower accuracy are more robust to edge cases. Always test thoroughly before replacing a working model.\n",
    "\n",
    "**Note**\n",
    "Overwriting the file makes it impossible to quickly roll back to the previous working version if the new model has issues. \n",
    "\n",
    "Excellent! By overwriting, you lost the 85% model that was working fine. Now you can't quickly switch back ‚Äî you'd have to retrain from scratch while customers experience problems with the buggy model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197f8fe4",
   "metadata": {},
   "source": [
    "**Building Your First Machine Learning Service**\n",
    "### actually making your model available for others to use. This is what we call \"serving\" a model, and it's the bridge between your experimental notebooks and real-world applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3d558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
